{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9561c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.8.1+cu111)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (0.9.1+cu111)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 15.4 MB/s            \n",
      "\u001B[?25hRequirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torch) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from torchvision) (8.3.2)\n",
      "  Downloading torchaudio-0.10.1-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 91.8 MB/s            \n",
      "\u001B[?25h  Downloading torchaudio-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
      "     |████████████████████████████████| 2.9 MB 92.6 MB/s            \n",
      "\u001B[?25h  Downloading torchaudio-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 107.1 MB/s            \n",
      "\u001B[?25h  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 112.5 MB/s            \n",
      "\u001B[?25h  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 30.1 MB/s            \n",
      "\u001B[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.8.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "     |████████████████████████████████| 3.5 MB 14.8 MB/s            \n",
      "\u001B[?25hCollecting datasets\n",
      "  Downloading datasets-1.18.3-py3-none-any.whl (311 kB)\n",
      "     |████████████████████████████████| 311 kB 56.1 MB/s            \n",
      "\u001B[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 15.5 MB/s            \n",
      "\u001B[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (3.3.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (4.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2021.11.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (4.62.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 70.5 MB/s            \n",
      "\u001B[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "     |████████████████████████████████| 6.8 MB 22.7 MB/s            \n",
      "\u001B[?25hRequirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 89.9 MB/s            \n",
      "\u001B[?25hRequirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (1.3.4)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
      "     |████████████████████████████████| 243 kB 96.8 MB/s            \n",
      "\u001B[?25hRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (2.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Installing collected packages: fsspec, xxhash, tokenizers, sacremoses, huggingface-hub, transformers, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.4.0\n",
      "    Uninstalling fsspec-2021.4.0:\n",
      "      Successfully uninstalled fsspec-2021.4.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2021.4.0 requires fsspec==2021.04.0, but you have fsspec 2022.1.0 which is incompatible.\u001B[0m\n",
      "Successfully installed datasets-1.18.3 fsspec-2022.1.0 huggingface-hub-0.4.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2 xxhash-2.0.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch torchvision torchaudio\n",
    "# !pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03522e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42c95cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test.csv')\n",
    "train = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796ab839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You guys provide EMI option?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you offer Zero Percent EMI payment options?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0% EMI.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EMI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I want in installment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence  label\n",
       "0                    You guys provide EMI option?      0\n",
       "1  Do you offer Zero Percent EMI payment options?      0\n",
       "2                                         0% EMI.      0\n",
       "3                                             EMI      0\n",
       "4                           I want in installment      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9077e26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pillows</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Down payments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I replace the mattress.</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tell me about the latest offers</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My order Number</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sentence  label\n",
       "0                          Pillows     19\n",
       "1                    Down payments      0\n",
       "2  How can I replace the mattress.     17\n",
       "3  Tell me about the latest offers     20\n",
       "4                  My order Number     16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_df = train_test_split(train, test_size=0.2, random_state=42, stratify=train['label'].tolist())\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "eval_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbc2c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>King Size</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distributors/Retailers/Showrooms</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can I get delivery on this pincode</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have any distributors in Mumbai city</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paisa Finance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      sentence  label\n",
       "0                                    King Size      8\n",
       "1             Distributors/Retailers/Showrooms     11\n",
       "2           Can I get delivery on this pincode     10\n",
       "3  Do you have any distributors in Mumbai city     11\n",
       "4                                Paisa Finance      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b35677f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label'],\n",
       "    num_rows: 262\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "softmattress_train = Dataset.from_pandas(train_df)\n",
    "softmattress_eval = Dataset.from_pandas(eval_df)\n",
    "softmattress_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a156ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d63d28be6974107bf41d8f2508f8889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3951eee1844e4286c1df5db31ce5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c921d981c54308b066bf421e911497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faaa56101544da2869beff02700d047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", padding=True, truncation=True, num_labels=21)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "489bde3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fd670263f54e159023a95a38b9be51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ec147867b74b1487f7671e06ff3649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': tensor(17),\n",
       " 'input_ids': tensor([  101,  2129,  2064,  1045,  5672,  1996, 13342,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_softmattress_train = softmattress_train.map(preprocess_function, batched=True)\n",
    "tokenized_softmattress_eval = softmattress_eval.map(preprocess_function, batched=True)\n",
    "\n",
    "columns_to_return = ['input_ids', 'label', 'attention_mask']\n",
    "tokenized_softmattress_train.set_format(type='torch', columns=columns_to_return)\n",
    "tokenized_softmattress_eval.set_format(type='torch', columns=columns_to_return)\n",
    "\n",
    "tokenized_softmattress_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc45e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f454e7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26c84b171a74cfcb5ad7f230f67cfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c989d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(labels, pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": accuracy,\"f1_score\":f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa81b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 262\n",
      "  Num Epochs = 25\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 425\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='425' max='425' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [425/425 00:49, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=425, training_loss=1.161474609375, metrics={'train_runtime': 65.3043, 'train_samples_per_second': 100.3, 'train_steps_per_second': 6.508, 'total_flos': 100996371639000.0, 'train_loss': 1.161474609375, 'epoch': 25.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=25,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_softmattress_train,\n",
    "    eval_dataset=tokenized_softmattress_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c9fb958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 66\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.48421910405158997,\n",
       " 'eval_accuracy': 0.9393939393939394,\n",
       " 'eval_f1_score': 0.9361231361231361,\n",
       " 'eval_runtime': 0.3833,\n",
       " 'eval_samples_per_second': 172.196,\n",
       " 'eval_steps_per_second': 13.045,\n",
       " 'epoch': 25.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "feaf9333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94e04b646984cea9559efdc06e71804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: sentence.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 397\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_node</th>\n",
       "      <th>predicted_node_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There are only 2 models</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>0.159618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Single</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.172722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What's difference between ergo and ortho</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.279291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Return order</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0.473220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hai not recieved my product</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0.573305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Trail option are there</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>0.716519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>I want to buy SOF ergo mattress</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.603088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Pillow extra shoft and support difference?</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>0.298042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Extra support and extra shift difference?</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>0.213597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>I am from nepal .you delivery your items in nepal</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.263355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label  predicted_node  \\\n",
       "0                              There are only 2 models     21               8   \n",
       "1                                               Single     21               0   \n",
       "2             What's difference between ergo and ortho      4               4   \n",
       "3                                         Return order     17              16   \n",
       "4                          Hai not recieved my product     15              17   \n",
       "..                                                 ...    ...             ...   \n",
       "392                             Trail option are there      6              11   \n",
       "393                    I want to buy SOF ergo mattress      3               3   \n",
       "394         Pillow extra shoft and support difference?     19               7   \n",
       "395          Extra support and extra shift difference?     21               7   \n",
       "396  I am from nepal .you delivery your items in nepal     10              10   \n",
       "\n",
       "     predicted_node_score  \n",
       "0                0.159618  \n",
       "1                0.172722  \n",
       "2                0.279291  \n",
       "3                0.473220  \n",
       "4                0.573305  \n",
       "..                    ...  \n",
       "392              0.716519  \n",
       "393              0.603088  \n",
       "394              0.298042  \n",
       "395              0.213597  \n",
       "396              0.263355  \n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "softmattress_test = Dataset.from_pandas(test)\n",
    "tokenized_softmattress_test = softmattress_test.map(preprocess_function, batched=True)\n",
    "\n",
    "columns_to_return = ['input_ids', 'attention_mask']\n",
    "tokenized_softmattress_test.set_format(type='torch', columns=columns_to_return)\n",
    "\n",
    "\n",
    "preds = trainer.predict(test_dataset=tokenized_softmattress_test)\n",
    "probs = torch.from_numpy(preds[0]).softmax(1)\n",
    "predictions = probs.numpy()\n",
    "top_predicted = np.argmax(predictions, axis=1)\n",
    "\n",
    "out_df = test\n",
    "out_df['predicted_node'] = [top_predicted[i] for i in range(len(test))]\n",
    "out_df['predicted_node_score'] = [predictions[i][top_predicted[i]] for i in range(len(test))]\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fde36332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.25\n",
    "count = 0\n",
    "for index, rows in out_df.iterrows():\n",
    "    if rows[3] > threshold:\n",
    "        if rows[1] == rows[2]:\n",
    "            count += 1\n",
    "    else:\n",
    "        if rows[1] == 21:\n",
    "            count += 1\n",
    "            \n",
    "\n",
    "print(count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p37",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}